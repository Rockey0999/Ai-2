<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MoodMirror AI - Live</title>
    
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    
    <style>
        body { background: #0a0e14; color: white; font-family: 'Segoe UI', sans-serif; text-align: center; margin: 0; padding: 20px; }
        .box { max-width: 600px; margin: auto; background: #161b22; padding: 20px; border-radius: 15px; border: 1px solid #30363d; }
        video { width: 100%; border-radius: 10px; background: #000; }
        #status { color: #00ff88; font-weight: bold; font-size: 1.2em; margin: 15px 0; }
        #advice { background: #0d1117; padding: 15px; border-radius: 8px; color: #58a6ff; min-height: 50px; }
        .loading { position: fixed; top: 0; left: 0; width: 100%; height: 100%; background: #0a0e14; display: flex; align-items: center; justify-content: center; z-index: 100; }
    </style>
</head>
<body>

<div id="loader" class="loading"><h2>üöÄ Waking up AI... Please Allow Camera</h2></div>

<div class="box">
    <h1>MOODMIRROR <span style="color:#00ff88">LIVE</span></h1>
    <video id="video" autoplay muted playsinline></video>
    
    <div id="status">DETECTING...</div>
    <div id="advice">Point the camera at your face to start.</div>
</div>

<script>
    const video = document.getElementById('video');
    const statusDiv = document.getElementById('status');
    const adviceDiv = document.getElementById('advice');

    // THIS IS YOUR PYTHON-STYLE LOGIC CONVERTED TO FAST JS FOR GITHUB
    function getAdvice(emo) {
        const recommendations = {
            'happy': "üöÄ FLOW STATE: You're in a great mood! Tackle your hardest math/science problems now.",
            'sad': "‚ö†Ô∏è FATIGUE: You look tired. Take a 15-minute power nap or a walk.",
            'angry': "üî• STRESS: High frustration detected. Stop studying for 10 mins and listen to music.",
            'surprised': "üí° ENGAGED: You look curious! Great time to learn new concepts.",
            'neutral': "‚úÖ STEADY: Good focus. Keep going, but remember to drink water.",
            'default': "Scanning your emotional state..."
        };
        return recommendations[emo] || recommendations['default'];
    }

    async function start() {
        try {
            // Load models from a reliable public mirror
            const MODEL_URL = 'https://vladmandic.github.io/face-api/model/';
            await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
            await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
            
            // Start Camera
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            
            document.getElementById('loader').style.display = 'none';
            
            // Loop Detection
            setInterval(async () => {
                const detect = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
                if (detect) {
                    const expressions = detect.expressions;
                    const topEmo = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
                    
                    statusDiv.innerText = "EMOTION: " + topEmo.toUpperCase();
                    adviceDiv.innerText = getAdvice(topEmo);
                }
            }, 500);

        } catch (err) {
            document.getElementById('loader').innerHTML = "<h2>‚ùå Error: Camera Denied or No Internet</h2>";
            console.error(err);
        }
    }

    start();
</script>
</body>
</html>
